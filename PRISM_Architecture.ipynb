{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt_Generation"
      ],
      "metadata": {
        "id": "kjxPSL3OW9Qc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWig3bD9gwMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87fb0ef-bbd3-4474-81a1-35762959d5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (9.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Collecting sqlite-utils\n",
            "  Downloading sqlite_utils-3.39-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Collecting sqlite-fts4 (from sqlite-utils)\n",
            "  Downloading sqlite_fts4-1.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click>=8.3.1 in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (8.3.1)\n",
            "Collecting click-default-group>=1.2.3 (from sqlite-utils)\n",
            "  Downloading click_default_group-1.2.4-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (2.9.0.post0)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (1.6.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (24.1.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->sqlite-utils) (1.17.0)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlite_utils-3.39-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_default_group-1.2.4-py2.py3-none-any.whl (4.1 kB)\n",
            "Downloading sqlite_fts4-1.0.3-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: sqlite-fts4, loguru, click-default-group, sqlite-utils\n",
            "Successfully installed click-default-group-1.2.4 loguru-0.7.3 sqlite-fts4-1.0.3 sqlite-utils-3.39\n"
          ]
        }
      ],
      "source": [
        "!pip install openai python-dotenv loguru tenacity requests beautifulsoup4 sqlite-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- INSTALL ----------\n",
        "!pip install --upgrade groq\n",
        "\n",
        "# ---------- SET API KEY (TEMPORARY ‚Äì DELETE LATER) ----------\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# ---------- TEST GROQ API ----------\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Generate 3 Google search queries on AI hallucination mitigation.\"}\n",
        "    ],\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Groq API is working!\\n\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWnG2GQyHh_h",
        "outputId": "39f5b142-eb61-4823-8355-f0f2be47e62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "‚úÖ Groq API is working!\n",
            "\n",
            "Here are three potential Google search queries related to AI hallucination mitigation:\n",
            "\n",
            "1. \"AI hallucination mitigation techniques for natural language processing\"\n",
            "2. \"Methods for reducing AI model overconfidence and hallucinations in decision-making applications\"\n",
            "3. \"Best practices for training AI models to avoid hallucinations and improve factual accuracy in text generation\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# PRISM ‚Äì Single Cell Working Demo\n",
        "# Groq API (Free) ‚Äì No Errors\n",
        "# ===============================\n",
        "\n",
        "# 1. Install required library\n",
        "!pip install --quiet --upgrade groq tenacity loguru\n",
        "\n",
        "# 2. Set API key (TEMPORARY ‚Äì remove later)\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# 3. Imports\n",
        "from groq import Groq\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "from loguru import logger\n",
        "import sys\n",
        "\n",
        "# 4. Logger setup\n",
        "logger.remove()\n",
        "logger.add(sys.stdout, level=\"INFO\")\n",
        "\n",
        "logger.info(\"Logger initialized\")\n",
        "\n",
        "# 5. Retry decorator\n",
        "def retry_api():\n",
        "    return retry(\n",
        "        stop=stop_after_attempt(3),\n",
        "        wait=wait_fixed(2),\n",
        "        reraise=True\n",
        "    )\n",
        "\n",
        "# 6. Initialize Groq client (reads key from env)\n",
        "client = Groq()\n",
        "\n",
        "# 7. LLM call function\n",
        "@retry_api()\n",
        "def call_llm(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",  # ‚úÖ supported model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a precise research assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# 8. Prompt template (PRISM ‚Äì T6)\n",
        "def search_prompt(topic):\n",
        "    return f\"\"\"\n",
        "Generate 3 concise Google search queries\n",
        "for latest verified information on:\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "Avoid blogs, opinions, and speculation.\n",
        "\"\"\"\n",
        "\n",
        "# 9. RUN PRISM TEST\n",
        "topic = \"AI hallucination mitigation\"\n",
        "\n",
        "logger.info(\"Calling Groq LLM...\")\n",
        "prompt = search_prompt(topic)\n",
        "output = call_llm(prompt)\n",
        "\n",
        "print(\"\\n================ RESULT ================\\n\")\n",
        "print(output)\n",
        "print(\"\\n========================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xgcWE71LsXa",
        "outputId": "b8923678-a74d-4bfe-eb88-ce59aa7e1965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-12-29 09:04:40.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLogger initialized\u001b[0m\n",
            "\u001b[32m2025-12-29 09:04:40.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mCalling Groq LLM...\u001b[0m\n",
            "\n",
            "================ RESULT ================\n",
            "\n",
            "Here are three concise Google search queries for the latest verified information on AI hallucination mitigation:\n",
            "\n",
            "1. **\"AI hallucination mitigation techniques peer-reviewed studies\"**\n",
            "This query targets academic research and peer-reviewed studies on AI hallucination mitigation, providing a reliable source of information.\n",
            "\n",
            "2. **\"AI model hallucination reduction methods ACM publications\"**\n",
            "This query focuses on publications from the Association for Computing Machinery (ACM), a reputable organization in the field of computer science, to find verified information on AI hallucination mitigation methods.\n",
            "\n",
            "3. **\"AI-generated text hallucination prevention strategies IEEE Transactions\"**\n",
            "This query targets IEEE Transactions, a well-established and respected publication in the field of electrical engineering and computer science, to find the latest verified information on AI-generated text hallucination prevention strategies.\n",
            "\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq()\n",
        "\n",
        "CANDIDATE_MODELS = [\n",
        "    \"mixtral-8x7b-32768\",\n",
        "    \"llama-3.1-8b-instant\"\n",
        "]\n",
        "\n",
        "def get_working_model():\n",
        "    for model in CANDIDATE_MODELS:\n",
        "        try:\n",
        "            client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": \"ping\"}],\n",
        "                max_tokens=5\n",
        "            )\n",
        "            return model\n",
        "        except Exception:\n",
        "            continue\n",
        "    raise RuntimeError(\"No supported Groq models available\")\n",
        "\n",
        "MODEL = get_working_model()\n",
        "print(\"‚úÖ Using model:\", MODEL)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Generate one search query on AI hallucination mitigation\"}]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwS_Z0imM6GY",
        "outputId": "eacf3909-57a9-46ab-8436-26849987ba58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using model: llama-3.1-8b-instant\n",
            "Here's a potential search query on AI hallucination mitigation:\n",
            "\n",
            "\"AI model hallucination detection techniques for natural language processing applications\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# Gemini SAFE Test ‚Äì Dynamic Model Picker\n",
        "# ======================================\n",
        "\n",
        "!pip install --quiet --upgrade google-generativeai\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# 1. Set your Gemini API key\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD8INnR4Y6ssTIaFdiwZWWFL8QclPAbPlI\"\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# 2. List available models\n",
        "print(\"üîç Available Gemini models:\\n\")\n",
        "\n",
        "available_models = []\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        available_models.append(m.name)\n",
        "        print(\"‚úÖ\", m.name)\n",
        "\n",
        "# 3. Pick the first usable model\n",
        "if not available_models:\n",
        "    raise RuntimeError(\"No Gemini models available for generateContent\")\n",
        "\n",
        "MODEL_NAME = available_models[0]\n",
        "print(f\"\\nüëâ Using model: {MODEL_NAME}\")\n",
        "\n",
        "# 4. Create model and test\n",
        "model = genai.GenerativeModel(MODEL_NAME)\n",
        "\n",
        "prompt = \"\"\"\n",
        "Generate 3 concise Google search queries\n",
        "for latest verified information on:\n",
        "\n",
        "Topic: AI hallucination mitigation\n",
        "\n",
        "Avoid blogs and speculation.\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(\"\\n‚úÖ Gemini Output:\\n\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "8SKYM9n5UI3C",
        "outputId": "1300b1b7-00de-4184-919c-0f1cb3f40202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Available Gemini models:\n",
            "\n",
            "‚úÖ models/gemini-2.5-flash\n",
            "‚úÖ models/gemini-2.5-pro\n",
            "‚úÖ models/gemini-2.0-flash-exp\n",
            "‚úÖ models/gemini-2.0-flash\n",
            "‚úÖ models/gemini-2.0-flash-001\n",
            "‚úÖ models/gemini-2.0-flash-exp-image-generation\n",
            "‚úÖ models/gemini-2.0-flash-lite-001\n",
            "‚úÖ models/gemini-2.0-flash-lite\n",
            "‚úÖ models/gemini-2.0-flash-lite-preview-02-05\n",
            "‚úÖ models/gemini-2.0-flash-lite-preview\n",
            "‚úÖ models/gemini-exp-1206\n",
            "‚úÖ models/gemini-2.5-flash-preview-tts\n",
            "‚úÖ models/gemini-2.5-pro-preview-tts\n",
            "‚úÖ models/gemma-3-1b-it\n",
            "‚úÖ models/gemma-3-4b-it\n",
            "‚úÖ models/gemma-3-12b-it\n",
            "‚úÖ models/gemma-3-27b-it\n",
            "‚úÖ models/gemma-3n-e4b-it\n",
            "‚úÖ models/gemma-3n-e2b-it\n",
            "‚úÖ models/gemini-flash-latest\n",
            "‚úÖ models/gemini-flash-lite-latest\n",
            "‚úÖ models/gemini-pro-latest\n",
            "‚úÖ models/gemini-2.5-flash-lite\n",
            "‚úÖ models/gemini-2.5-flash-image-preview\n",
            "‚úÖ models/gemini-2.5-flash-image\n",
            "‚úÖ models/gemini-2.5-flash-preview-09-2025\n",
            "‚úÖ models/gemini-2.5-flash-lite-preview-09-2025\n",
            "‚úÖ models/gemini-3-pro-preview\n",
            "‚úÖ models/gemini-3-flash-preview\n",
            "‚úÖ models/gemini-3-pro-image-preview\n",
            "‚úÖ models/nano-banana-pro-preview\n",
            "‚úÖ models/gemini-robotics-er-1.5-preview\n",
            "‚úÖ models/gemini-2.5-computer-use-preview-10-2025\n",
            "‚úÖ models/deep-research-pro-preview-12-2025\n",
            "\n",
            "üëâ Using model: models/gemini-2.5-flash\n",
            "\n",
            "‚úÖ Gemini Output:\n",
            "\n",
            "Here are 3 concise Google search queries for the latest verified information on AI hallucination mitigation, avoiding blogs and speculation:\n",
            "\n",
            "1.  **AI hallucination mitigation research papers**\n",
            "2.  **Effective AI hallucination prevention techniques**\n",
            "3.  **Official reports AI hallucination solutions**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assuming call_llm and model are defined in previous cells and accessible\n",
        "groq_call = call_llm\n",
        "\n",
        "def gemini_call(prompt_text):\n",
        "    response = model.generate_content(prompt_text)\n",
        "    return response.text\n",
        "\n",
        "models = {\n",
        "    \"Groq_LLaMA_3.1_8B\": groq_call,\n",
        "    \"Gemini_2.5_Flash\": gemini_call\n",
        "}\n",
        "\n",
        "for model_name, model_fn in models.items():\n",
        "    start = time.time()\n",
        "    output = model_fn(prompt)\n",
        "    latency = time.time() - start\n",
        "\n",
        "    print(model_name)\n",
        "    print(\"Latency:\", round(latency, 2))\n",
        "    print(\"Output:\\n\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "eGmBW9a_UvpY",
        "outputId": "1082873b-b70f-430c-98c6-eaeffdb1c193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Groq_LLaMA_3.1_8B\n",
            "Latency: 0.37\n",
            "Output:\n",
            " Here are three concise Google search queries for the latest verified information on AI hallucination mitigation:\n",
            "\n",
            "1. **\"AI hallucination mitigation techniques peer-reviewed studies\"**\n",
            "   This query aims to find the latest research on AI hallucination mitigation techniques that have been verified through peer-reviewed studies.\n",
            "\n",
            "2. **\"AI model reliability and trustworthiness metrics\"**\n",
            "   This query seeks to find the latest information on metrics used to measure the reliability and trustworthiness of AI models, which can help mitigate AI hallucinations.\n",
            "\n",
            "3. **\"AI hallucination detection and correction methods ACM/IEEE publications\"**\n",
            "   This query targets publications from reputable sources like ACM (Association for Computing Machinery) and IEEE (Institute of Electrical and Electronics Engineers) to find the latest verified methods for detecting and correcting AI hallucinations.\n",
            "Gemini_2.5_Flash\n",
            "Latency: 11.08\n",
            "Output:\n",
            " Here are 3 concise Google search queries for the latest verified information on AI hallucination mitigation, designed to filter out blogs and speculation:\n",
            "\n",
            "1.  `AI hallucination mitigation \"research paper\"`\n",
            "2.  `latest LLM hallucination prevention techniques`\n",
            "3.  `AI hallucination \"peer-reviewed\"`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WEB Crawling"
      ],
      "metadata": {
        "id": "ORmM2sqyTmf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZspcVUQuTrhI",
        "outputId": "72d1a80e-075c-4fd0-9103-41723792cc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=2e964b777369ff73d4eb0831d5ae6fcd29b5459a245a677183f1c843228847b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "OrkLDdGxTqBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë Put your SerpAPI key here\n",
        "SERP_API_KEY = \"eff94acd3beb63e96835b28fb950fed50a12dbf388e82b43a98dcf5de54e9122\"\n"
      ],
      "metadata": {
        "id": "oeZekwzqTyYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def google_search(query, num_results=5):\n",
        "    params = {\n",
        "        \"engine\": \"google\",\n",
        "        \"q\": query,\n",
        "        \"num\": num_results,\n",
        "        \"api_key\": SERP_API_KEY\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "\n",
        "    links = []\n",
        "    for r in results.get(\"organic_results\", []):\n",
        "        links.append({\n",
        "            \"title\": r.get(\"title\"),\n",
        "            \"link\": r.get(\"link\"),\n",
        "            \"source\": r.get(\"source\", \"unknown\")\n",
        "        })\n",
        "    return links\n"
      ],
      "metadata": {
        "id": "njUFhiXGTyL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visited_urls = set()\n",
        "\n",
        "def is_new_url(url):\n",
        "    if url in visited_urls:\n",
        "        return False\n",
        "    visited_urls.add(url)\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "rJCY7Bh9TyIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_article(url):\n",
        "    try:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        r = requests.get(url, headers=headers, timeout=10)\n",
        "\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "        text = \" \".join(p.get_text() for p in paragraphs)\n",
        "        return text[:4000]   # limit size for LLM later\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Scraping failed:\", e)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "ZMUrtJM3TyFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_crawler(topic):\n",
        "    print(f\"\\nüîç Searching topic: {topic}\\n\")\n",
        "\n",
        "    results = google_search(topic, num_results=5)\n",
        "\n",
        "    for r in results:\n",
        "        url = r[\"link\"]\n",
        "\n",
        "        if not is_new_url(url):\n",
        "            print(\"‚è≠ Duplicate skipped:\", url)\n",
        "            continue\n",
        "\n",
        "        print(\"\\nüåê Title:\", r[\"title\"])\n",
        "        print(\"üîó URL:\", url)\n",
        "\n",
        "        content = scrape_article(url)\n",
        "\n",
        "        if content:\n",
        "            print(\"‚úÖ Extracted characters:\", len(content))\n",
        "            print(\"üìÑ Sample text:\\n\", content[:500])\n",
        "        else:\n",
        "            print(\"‚ùå Failed to extract content\")\n"
      ],
      "metadata": {
        "id": "F4ofKeiMTx_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_crawler(\"recent counter UAV technologies military research\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rkPy5HwTxyt",
        "outputId": "68c01b19-6127-4152-81fa-5fe75ec4a03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Searching topic: recent counter UAV technologies military research\n",
            "\n",
            "\n",
            "üåê Title: Rapidly Developed Counter-Drone Prototype Succeeds at ...\n",
            "üîó URL: https://www.navy.mil/Press-Office/News-Stories/display-news/Article/4359959/rapidly-developed-counter-drone-prototype-succeeds-at-natos-bold-machina/\n",
            "‚úÖ Extracted characters: 166\n",
            "üìÑ Sample text:\n",
            " \n",
            "Reference #18.9363ca17.1766998453.378af09f\n",
            "https://errors.edgesuite.net/18.9363ca17.1766998453.378af09f\n",
            " https://errors.edgesuite.net/18.9363ca17.1766998453.378af09f\n",
            "\n",
            "üåê Title: S&T Joins New Cross-Government Collaboration to ...\n",
            "üîó URL: https://www.dhs.gov/science-and-technology/news/2025/12/22/st-joins-new-cross-government-collaboration-counter-drone-threats\n",
            "‚úÖ Extracted characters: 4000\n",
            "üìÑ Sample text:\n",
            " An official website of the United States government Here‚Äôs how you know \n",
            "\n",
            "                Official websites use .gov              \n",
            "\n",
            "                              A .gov website belongs to an official government organization in the United States.\n",
            "                           \n",
            "\n",
            "                Secure .gov websites use HTTPS              \n",
            "\n",
            "              A lock\n",
            "                (LockA locked padlock)\n",
            "                or https:// means you‚Äôve safely connected to the .gov website. Share sensitive informat\n",
            "\n",
            "üåê Title: Dozens of Federal Agencies Initiate Counter-UAS ...\n",
            "üîó URL: https://www.war.gov/News/News-Stories/Article/Article/4343888/dozens-of-federal-agencies-initiate-counter-uas-collaboration/\n",
            "‚úÖ Extracted characters: 166\n",
            "üìÑ Sample text:\n",
            " \n",
            "Reference #18.8651c317.1766998454.203613ec\n",
            "https://errors.edgesuite.net/18.8651c317.1766998454.203613ec\n",
            " https://errors.edgesuite.net/18.8651c317.1766998454.203613ec\n",
            "\n",
            "üåê Title: Advancements in Counter-UAV Technology Powering ...\n",
            "üîó URL: https://www.alm.com/press_release/alm-intelligence-updates-verdictsearch/?s-news-15721128-2025-12-01-advancements-in-counter-uav-technology-powering-future-of-drone-defense\n",
            "‚úÖ Extracted characters: 2597\n",
            "üìÑ Sample text:\n",
            " Press Release VerdictSearch Modernizes Verdict Cases and Settlements Tool New York, NY ‚Äì July 10, 2018 ‚Äî ALM Intelligence has released an upgraded version of VerdictSearch, the leading case-research tool for attorneys and insurers. VerdictSearch provides case-winning information for personal-injury attorneys on the plaintiff and defense side. The VerdictSearch database has more than 200,000 intricately fielded reports, and its user interface allows unparalleled specificity in searches. ‚ÄúIn the u\n"
          ]
        }
      ]
    }
  ]
}